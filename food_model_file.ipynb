{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6dd394",
   "metadata": {},
   "source": [
    "[DATASET LINK]](https://www.kaggle.com/datasets/deeprodge/indian-food-images-12-different-dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723378b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"food-dataset\"\n",
    "dataset = [\"train\", \"test\", \"val\"]\n",
    "items = ['Biryani', 'Butter Naan', 'Chai', 'Chole Bhature', 'Dhokla', 'Gulab Jamun', 'Jalebi', 'Momos', 'Paneer Sabzi', 'Pav Bhaji', 'Rasgulla', 'Samosa']\n",
    "\n",
    "x , y = [] , []\n",
    "for data in dataset:\n",
    "    for index, item in enumerate(items):\n",
    "        path = os.path.join(basepath, data, item)\n",
    "        try:\n",
    "            for filename in os.listdir(path):\n",
    "                filepath = os.path.join(path, filename)\n",
    "                img = Image.open(filepath).convert(\"RGB\").resize([256,256])\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                x.append(img_array)\n",
    "                y.append(index)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, dtype=\"float32\").reshape(-1, 256, 256, 3)\n",
    "x = x / 255.0\n",
    "\n",
    "y = np.array(y, dtype=\"int32\")\n",
    "\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(\"x_val shape:\", x_val.shape)\n",
    "print(\"y_val shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense , BatchNormalization, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42421ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(12, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3141ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device(\"CPU\"): # type: ignore\n",
    "    x_train = tf.convert_to_tensor(x_train)\n",
    "    y_train = tf.convert_to_tensor(y_train)\n",
    "    x_test = tf.convert_to_tensor(x_test)\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "    x_val = tf.convert_to_tensor(x_val)\n",
    "    y_val = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,       \n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4134d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau # type: ignore\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,        \n",
    "    patience=5,        \n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    validation_data =   (x_val, y_val), \n",
    "    batch_size      =   8, \n",
    "    epochs          =   100, \n",
    "    callbacks       =   [early_stop, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c1ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss'] # type: ignore\n",
    "accuracy = history.history['accuracy'] # type: ignore\n",
    "val_loss = history.history.get('val_loss', None) # type: ignore\n",
    "val_accuracy = history.history.get('val_accuracy', None) # type: ignore\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "if val_loss:\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')\n",
    "if val_accuracy:\n",
    "    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=8)\n",
    "print(f\"Test Loss: {test_loss},\\n Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"food_model_68%.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef705ef",
   "metadata": {},
   "source": [
    "<===== TESTING =====> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7884308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"food_model_83%.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath : str):\n",
    "   img =  Image.open(filepath).convert(\"RGB\").resize([256,256])\n",
    "   img_array = np.array(img)\n",
    "   img_array = np.array(img_array / 255, dtype=\"float32\")\n",
    "   img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "   res =  model.predict(img_array)\n",
    "   predicted_class = np.argmax(res, axis=1)\n",
    "\n",
    "   items = ['Biryani', 'Butter Naan', 'Chai', 'Chole Bhature', 'Dhokla', 'Gulab Jamun', 'Jalebi', 'Momos', 'Paneer Sabzi', 'Pav Bhaji', 'Rasgulla', 'Samosa']\n",
    "   class_name = items[predicted_class[0]]\n",
    "\n",
    "   print(\"Predicted Class: \", predicted_class[0], \" ==> \", class_name)\n",
    "\n",
    "   return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "   path = input(\"Enter the filepath : \")\n",
    "   if os.path.exists(path):\n",
    "      pred = predict(path)\n",
    "      print(f\"Model predicted : {pred}\")\n",
    "   else:\n",
    "       print(\"File not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
